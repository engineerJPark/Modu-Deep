{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PackedSequence, PaddedSequence\n",
    "\n",
    "[링크: PackedSequence에 대한 PyTorch 공식 문서](https://pytorch.org/docs/stable/nn.html#packedsequence)\n",
    "\n",
    "이 튜토리얼에서는 RNN / LSTM 계열의 모델에서 sequence batch를 잘 활용할 수 있는 `PackedSequence` 와 `PaddedSequence`를 만드는 법을 배워보겠습니다.\n",
    "\n",
    "PyTorch 라이브러리 안에는 다음 4가지 함수들이 주어집니다.\n",
    "\n",
    "`pad_sequence`, `pack_sequence`, `pack_padded_sequence`, `pad_packed_sequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_set: ['<pad>', 'w', 'd', 'i', 'a', 'm', 'e', 'h', 'o', 's', 'n', 'g', 'u', 'c', 'p', ' ', 'l', 'r', 't']\n",
      "char_set length: 19\n"
     ]
    }
   ],
   "source": [
    "# example data generating. batch size = 5, longest seq = 13\n",
    "# Random word from random word generator\n",
    "data = ['hello world',\n",
    "        'midnight',\n",
    "        'calculation',\n",
    "        'path',\n",
    "        'short circuit']\n",
    "\n",
    "# Make dictionary\n",
    "# 다음과 같이 해석한다 : char (for seq in (data for char in seq))\n",
    "char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token \n",
    "char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n",
    "print('char_set:', char_set)\n",
    "print('char_set length:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  6, 16, 16,  8, 15,  1,  8, 17, 16,  2])\n",
      "tensor([ 5,  3,  2, 10,  3, 11,  7, 18])\n",
      "tensor([13,  4, 16, 13, 12, 16,  4, 18,  3,  8, 10])\n",
      "tensor([14,  4, 18,  7])\n",
      "tensor([ 9,  7,  8, 17, 18, 15, 13,  3, 17, 13, 12,  3, 18])\n",
      "[tensor([ 7,  6, 16, 16,  8, 15,  1,  8, 17, 16,  2]), tensor([ 5,  3,  2, 10,  3, 11,  7, 18]), tensor([13,  4, 16, 13, 12, 16,  4, 18,  3,  8, 10]), tensor([14,  4, 18,  7]), tensor([ 9,  7,  8, 17, 18, 15, 13,  3, 17, 13, 12,  3, 18])]\n"
     ]
    }
   ],
   "source": [
    "# Convert character to index and make list of tensors\n",
    "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
    "\n",
    "# Check converted result\n",
    "for sequence in X:\n",
    "    print(sequence)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths: [11, 8, 11, 4, 13]\n"
     ]
    }
   ],
   "source": [
    "# 위의 tensor는 모두 그 size가 제각각이다.\n",
    "# Make length tensor (will be used later in 'pack_padded_sequence' function)\n",
    "lengths = [len(seq) for seq in X]\n",
    "print('lengths:', lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 batch로 만들어주기 위해서 일반적으로 제일 긴 sequence 길이에 맞춰 뒷부분에 padding을 추가(일반적으로 많이 쓰이는 Padding 방식)\n",
    "\n",
    "PyTorch에서는 `PackedSequence`라는 것을 쓰면 padding 없이도 정확히 필요한 부분까지만 병렬 계산을 할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pad_sequence` 함수를 이용하여 PaddedSequence (그냥 Tensor) 만들기\n",
    "\n",
    "따로 PaddedSequence라는 class는 존재하지 않고, PaddedSequence는 sequence중에서 가장 긴 sequence와 길이를 맞추어주기 위해 padding을 추가한 일반적인 **Tensor**를 말한다.\n",
    "\n",
    "이때, `pad_sequence`라는 PyTorch 기본 라이브러리 함수를 이용한다. input이 **Tensor들의 list**이다.\n",
    "\n",
    "list 안에 있는 각각의 Tensor들의 shape가 `(?, a, b, ...)` 라고 할때, (여기서 ?는 각각 다른 sequence length 입니다.)\n",
    "\n",
    "input Tensor의 shape = `(sequence length, a, b, ...)`\n",
    "\n",
    "output Tensor shape = `(longest sequence length in the batch, batch_size, a, b, ...)`\n",
    "\n",
    "`batch_first=True`이면 `(batch_size, longest sequence length in the batch, a, b, ...)` shape를 가지는 Tensor가 리턴된다.\n",
    "\n",
    "`padding_value=42`와 같이 파라미터를 지정해주면, padding하는 값도 정해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  6, 16, 16,  8, 15,  1,  8, 17, 16,  2,  0,  0],\n",
      "        [ 5,  3,  2, 10,  3, 11,  7, 18,  0,  0,  0,  0,  0],\n",
      "        [13,  4, 16, 13, 12, 16,  4, 18,  3,  8, 10,  0,  0],\n",
      "        [14,  4, 18,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  7,  8, 17, 18, 15, 13,  3, 17, 13, 12,  3, 18]])\n",
      "torch.Size([5, 13])\n",
      "tensor([[ 7,  5, 13, 14,  9],\n",
      "        [ 6,  3,  4,  4,  7],\n",
      "        [16,  2, 16, 18,  8],\n",
      "        [16, 10, 13,  7, 17],\n",
      "        [ 8,  3, 12,  0, 18],\n",
      "        [15, 11, 16,  0, 15],\n",
      "        [ 1,  7,  4,  0, 13],\n",
      "        [ 8, 18, 18,  0,  3],\n",
      "        [17,  0,  3,  0, 17],\n",
      "        [16,  0,  8,  0, 13],\n",
      "        [ 2,  0, 10,  0, 12],\n",
      "        [ 0,  0,  0,  0,  3],\n",
      "        [ 0,  0,  0,  0, 18]])\n",
      "torch.Size([13, 5])\n"
     ]
    }
   ],
   "source": [
    "# Make a Tensor of shape (Batch x Maximum_Sequence_Length)\n",
    "padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n",
    "print(padded_sequence)\n",
    "print(padded_sequence.shape)\n",
    "\n",
    "padded_sequence = pad_sequence(X) # X is now padded sequence\n",
    "print(padded_sequence)\n",
    "print(padded_sequence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `pack_sequence` 함수를 이용하여 PackedSequence 만들기\n",
    "\n",
    "padding을 추가하지 않고 정확히 주어진 sequence 길이까지만 모델이 연산을 하게끔 만드는 PyTorch의 자료구조이다.\n",
    "\n",
    "주어지는 input (list of Tensor)는 길이에 따른 내림차순으로 정렬이 되어있어야 한다.\n",
    "\n",
    "sorted 함수에 대해서는 다음 링크를 확인\n",
    "\n",
    "https://blockdmask.tistory.com/466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9,  7,  8, 17, 18, 15, 13,  3, 17, 13, 12,  3, 18])\n",
      "tensor([ 7,  6, 16, 16,  8, 15,  1,  8, 17, 16,  2])\n",
      "tensor([13,  4, 16, 13, 12, 16,  4, 18,  3,  8, 10])\n",
      "tensor([ 5,  3,  2, 10,  3, 11,  7, 18])\n",
      "tensor([14,  4, 18,  7])\n"
     ]
    }
   ],
   "source": [
    "# Sort by descending lengths\n",
    "sorted_idx = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True) # docu 참고\n",
    "sorted_X = [X[idx] for idx in sorted_idx] # sorting한 결과\n",
    "\n",
    "# Check converted result\n",
    "for sequence in sorted_X:\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([ 9,  7, 13,  5, 14,  7,  6,  4,  3,  4,  8, 16, 16,  2, 18, 17, 16, 13,\n",
      "        10,  7, 18,  8, 12,  3, 15, 15, 16, 11, 13,  1,  4,  7,  3,  8, 18, 18,\n",
      "        17, 17,  3, 13, 16,  8, 12,  2, 10,  3, 18]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "torch.Size([47])\n"
     ]
    }
   ],
   "source": [
    "packed_sequence = pack_sequence(sorted_X)\n",
    "print(packed_sequence) # 여기서의 batch_size는 각 sequence를 처리하는 step 마다의 batch를 의미한다. 함수값으로 입력되는 sequence의 length가 아니라!\n",
    "print(packed_sequence.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN에 투입하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 5, 19])\n"
     ]
    }
   ],
   "source": [
    "# character의 index를 one-hot character embedding한 값을 RNN의 input으로 넣어준다.\n",
    "# one-hot embedding using PaddedSequence\n",
    "eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n",
    "embedded_tensor = eye[padded_sequence]\n",
    "print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 19])\n"
     ]
    }
   ],
   "source": [
    "# one-hot embedding using PackedSequence\n",
    "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
    "print(embedded_packed_seq.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 모델에 투입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare RNN\n",
    "rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PaddedSequence`를 이용하여 RNN에 넣어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 5, 30])\n",
      "torch.Size([1, 13, 30])\n"
     ]
    }
   ],
   "source": [
    "rnn_output, hidden = rnn(embedded_tensor)\n",
    "print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n",
    "print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PackedSequence`를 이용하여 RNN에 넣어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 30])\n",
      "torch.Size([1, 5, 30])\n"
     ]
    }
   ],
   "source": [
    "rnn_output, hidden = rnn(embedded_packed_seq)\n",
    "print(rnn_output.data.shape)\n",
    "print(hidden.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n",
      "tensor([13, 11, 11,  8,  4])\n"
     ]
    }
   ],
   "source": [
    "#`pad_packed_sequence` -> (Tensor, list_of_lengths)\n",
    "\n",
    "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
    "print(unpacked_sequence.shape)\n",
    "print(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n",
      "[13, 11, 11, 8, 4]\n",
      "torch.Size([47, 19])\n",
      "tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# `pack_padded_sequence` : sequence 길이반드시 input, input sequence가 내림차순 정렬 되어있어야함\n",
    "\n",
    "# sorting\n",
    "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
    "print(embedded_padded_sequence.shape)\n",
    "\n",
    "# pack_padded_sequence\n",
    "sorted_lengths = sorted(lengths, reverse=True)\n",
    "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
    "print(sorted_lengths)\n",
    "print(new_packed_sequence.data.shape)\n",
    "print(new_packed_sequence.batch_sizes) # 여기서의 batch_size는 각 sequence를 처리하는 step 마다의 batch를 의미한다. 함수값으로 입력되는 sequence의 length가 아니라!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
