{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 W: 0.000, Cost: 4.666667\n",
      "Epoch    1/100 W: 0.140, Cost: 3.451467\n",
      "Epoch    2/100 W: 0.260, Cost: 2.552705\n",
      "Epoch    3/100 W: 0.364, Cost: 1.887980\n",
      "Epoch    4/100 W: 0.453, Cost: 1.396350\n",
      "Epoch    5/100 W: 0.530, Cost: 1.032741\n",
      "Epoch    6/100 W: 0.595, Cost: 0.763815\n",
      "Epoch    7/100 W: 0.652, Cost: 0.564918\n",
      "Epoch    8/100 W: 0.701, Cost: 0.417813\n",
      "Epoch    9/100 W: 0.743, Cost: 0.309015\n",
      "Epoch   10/100 W: 0.779, Cost: 0.228547\n",
      "Epoch   11/100 W: 0.810, Cost: 0.169034\n",
      "Epoch   12/100 W: 0.836, Cost: 0.125017\n",
      "Epoch   13/100 W: 0.859, Cost: 0.092463\n",
      "Epoch   14/100 W: 0.879, Cost: 0.068385\n",
      "Epoch   15/100 W: 0.896, Cost: 0.050578\n",
      "Epoch   16/100 W: 0.910, Cost: 0.037407\n",
      "Epoch   17/100 W: 0.923, Cost: 0.027667\n",
      "Epoch   18/100 W: 0.934, Cost: 0.020462\n",
      "Epoch   19/100 W: 0.943, Cost: 0.015134\n",
      "Epoch   20/100 W: 0.951, Cost: 0.011193\n",
      "Epoch   21/100 W: 0.958, Cost: 0.008278\n",
      "Epoch   22/100 W: 0.964, Cost: 0.006123\n",
      "Epoch   23/100 W: 0.969, Cost: 0.004528\n",
      "Epoch   24/100 W: 0.973, Cost: 0.003349\n",
      "Epoch   25/100 W: 0.977, Cost: 0.002477\n",
      "Epoch   26/100 W: 0.980, Cost: 0.001832\n",
      "Epoch   27/100 W: 0.983, Cost: 0.001355\n",
      "Epoch   28/100 W: 0.985, Cost: 0.001002\n",
      "Epoch   29/100 W: 0.987, Cost: 0.000741\n",
      "Epoch   30/100 W: 0.989, Cost: 0.000548\n",
      "Epoch   31/100 W: 0.991, Cost: 0.000405\n",
      "Epoch   32/100 W: 0.992, Cost: 0.000300\n",
      "Epoch   33/100 W: 0.993, Cost: 0.000222\n",
      "Epoch   34/100 W: 0.994, Cost: 0.000164\n",
      "Epoch   35/100 W: 0.995, Cost: 0.000121\n",
      "Epoch   36/100 W: 0.996, Cost: 0.000090\n",
      "Epoch   37/100 W: 0.996, Cost: 0.000066\n",
      "Epoch   38/100 W: 0.997, Cost: 0.000049\n",
      "Epoch   39/100 W: 0.997, Cost: 0.000036\n",
      "Epoch   40/100 W: 0.998, Cost: 0.000027\n",
      "Epoch   41/100 W: 0.998, Cost: 0.000020\n",
      "Epoch   42/100 W: 0.998, Cost: 0.000015\n",
      "Epoch   43/100 W: 0.998, Cost: 0.000011\n",
      "Epoch   44/100 W: 0.999, Cost: 0.000008\n",
      "Epoch   45/100 W: 0.999, Cost: 0.000006\n",
      "Epoch   46/100 W: 0.999, Cost: 0.000004\n",
      "Epoch   47/100 W: 0.999, Cost: 0.000003\n",
      "Epoch   48/100 W: 0.999, Cost: 0.000002\n",
      "Epoch   49/100 W: 0.999, Cost: 0.000002\n",
      "Epoch   50/100 W: 0.999, Cost: 0.000001\n",
      "Epoch   51/100 W: 1.000, Cost: 0.000001\n",
      "Epoch   52/100 W: 1.000, Cost: 0.000001\n",
      "Epoch   53/100 W: 1.000, Cost: 0.000001\n",
      "Epoch   54/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   55/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   56/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   57/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   58/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   59/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   60/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   61/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   62/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   63/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   64/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   65/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   66/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   67/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   68/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   69/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   70/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   71/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   72/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   73/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   74/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   75/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   76/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   77/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   78/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   79/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   80/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   81/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   82/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   83/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   84/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   85/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   86/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   87/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   88/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   89/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   90/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   91/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   92/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   93/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   94/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   95/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   96/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   97/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   98/100 W: 1.000, Cost: 0.000000\n",
      "Epoch   99/100 W: 1.000, Cost: 0.000000\n",
      "Epoch  100/100 W: 1.000, Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[1],[2],[3]])\n",
    "\n",
    "W = torch.zeros(1)\n",
    "lr = 0.01\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    hypothesis = x_train * W\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    gradient = torch.sum((W * x_train - y_train) * x_train)\n",
    "    \n",
    "    print('Epoch {:4d}/{} W: {:.3f}, Cost: {:.6f}'.format(epoch, nb_epochs, W.item(), cost.item()))\n",
    "    \n",
    "    W -= lr * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음과 같이 할수도 있다.\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[1],[2],[3]])\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "optimizer = optim.SGD([W], lr=0.01)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    hypothesis = x_train * W\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "        \n",
    "    print('Epoch {:4d}/{} W: {:.3f}, Cost: {:.6f}'.format(epoch, nb_epochs, W.item(), cost.item()))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
