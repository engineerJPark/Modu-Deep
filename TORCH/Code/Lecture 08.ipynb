{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} : {} 0 0.7260097861289978\n",
      "{} : {} 100 0.6983544230461121\n",
      "{} : {} 200 0.6955159902572632\n",
      "{} : {} 300 0.6942253708839417\n",
      "{} : {} 400 0.6936377882957458\n",
      "{} : {} 500 0.6933704614639282\n",
      "{} : {} 600 0.6932488679885864\n",
      "{} : {} 700 0.6931935548782349\n",
      "{} : {} 800 0.6931682825088501\n",
      "{} : {} 900 0.6931567788124084\n",
      "{} : {} 1000 0.6931515336036682\n",
      "{} : {} 1100 0.6931490898132324\n",
      "{} : {} 1200 0.6931480765342712\n",
      "{} : {} 1300 0.6931475400924683\n",
      "{} : {} 1400 0.6931473612785339\n",
      "{} : {} 1500 0.6931473016738892\n",
      "{} : {} 1600 0.6931472420692444\n",
      "{} : {} 1700 0.6931471824645996\n",
      "{} : {} 1800 0.6931471824645996\n",
      "{} : {} 1900 0.6931471824645996\n",
      "{} : {} 2000 0.6931471824645996\n",
      "{} : {} 2100 0.6931471824645996\n",
      "{} : {} 2200 0.6931471824645996\n",
      "{} : {} 2300 0.6931471824645996\n",
      "{} : {} 2400 0.6931471824645996\n",
      "{} : {} 2500 0.6931472420692444\n",
      "{} : {} 2600 0.6931471824645996\n",
      "{} : {} 2700 0.6931471824645996\n",
      "{} : {} 2800 0.6931471824645996\n",
      "{} : {} 2900 0.6931471824645996\n",
      "{} : {} 3000 0.6931471228599548\n",
      "{} : {} 3100 0.6931471824645996\n",
      "{} : {} 3200 0.6931471824645996\n",
      "{} : {} 3300 0.6931471824645996\n",
      "{} : {} 3400 0.6931471228599548\n",
      "{} : {} 3500 0.6931471824645996\n",
      "{} : {} 3600 0.6931471824645996\n",
      "{} : {} 3700 0.6931471824645996\n",
      "{} : {} 3800 0.6931471824645996\n",
      "{} : {} 3900 0.6931471824645996\n",
      "{} : {} 4000 0.6931471824645996\n",
      "{} : {} 4100 0.6931471824645996\n",
      "{} : {} 4200 0.6931471824645996\n",
      "{} : {} 4300 0.6931471824645996\n",
      "{} : {} 4400 0.6931471824645996\n",
      "{} : {} 4500 0.6931471824645996\n",
      "{} : {} 4600 0.6931471824645996\n",
      "{} : {} 4700 0.6931471824645996\n",
      "{} : {} 4800 0.6931471824645996\n",
      "{} : {} 4900 0.6931471824645996\n",
      "{} : {} 5000 0.6931471824645996\n",
      "{} : {} 5100 0.6931471824645996\n",
      "{} : {} 5200 0.6931471824645996\n",
      "{} : {} 5300 0.6931471824645996\n",
      "{} : {} 5400 0.6931471824645996\n",
      "{} : {} 5500 0.6931471824645996\n",
      "{} : {} 5600 0.6931471824645996\n",
      "{} : {} 5700 0.6931471824645996\n",
      "{} : {} 5800 0.6931471824645996\n",
      "{} : {} 5900 0.6931471824645996\n",
      "{} : {} 6000 0.6931471824645996\n",
      "{} : {} 6100 0.6931471824645996\n",
      "{} : {} 6200 0.6931471824645996\n",
      "{} : {} 6300 0.6931471824645996\n",
      "{} : {} 6400 0.6931471824645996\n",
      "{} : {} 6500 0.6931471824645996\n",
      "{} : {} 6600 0.6931471824645996\n",
      "{} : {} 6700 0.6931471824645996\n",
      "{} : {} 6800 0.6931471824645996\n",
      "{} : {} 6900 0.6931471824645996\n",
      "{} : {} 7000 0.6931471824645996\n",
      "{} : {} 7100 0.6931471824645996\n",
      "{} : {} 7200 0.6931471824645996\n",
      "{} : {} 7300 0.6931471824645996\n",
      "{} : {} 7400 0.6931471824645996\n",
      "{} : {} 7500 0.6931471824645996\n",
      "{} : {} 7600 0.6931471824645996\n",
      "{} : {} 7700 0.6931471824645996\n",
      "{} : {} 7800 0.6931471824645996\n",
      "{} : {} 7900 0.6931471824645996\n",
      "{} : {} 8000 0.6931471824645996\n",
      "{} : {} 8100 0.6931471824645996\n",
      "{} : {} 8200 0.6931471824645996\n",
      "{} : {} 8300 0.6931471824645996\n",
      "{} : {} 8400 0.6931471824645996\n",
      "{} : {} 8500 0.6931471824645996\n",
      "{} : {} 8600 0.6931471824645996\n",
      "{} : {} 8700 0.6931471824645996\n",
      "{} : {} 8800 0.6931471824645996\n",
      "{} : {} 8900 0.6931471824645996\n",
      "{} : {} 9000 0.6931471824645996\n",
      "{} : {} 9100 0.6931471824645996\n",
      "{} : {} 9200 0.6931471824645996\n",
      "{} : {} 9300 0.6931471824645996\n",
      "{} : {} 9400 0.6931471824645996\n",
      "{} : {} 9500 0.6931471824645996\n",
      "{} : {} 9600 0.6931471824645996\n",
      "{} : {} 9700 0.6931471824645996\n",
      "{} : {} 9800 0.6931471824645996\n",
      "{} : {} 9900 0.6931471824645996\n",
      "{} : {} 10000 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "# XOR by Single Layer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)\n",
    "Y = torch.tensor([[0],[1],[1],[0]], dtype=torch.float32)\n",
    "\n",
    "linear = torch.nn.Linear(2,1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = nn.Sequential(linear, sigmoid)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "for epoch in range(10000 + 1):\n",
    "    cost = F.binary_cross_entropy(model(X), Y)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"{} : {}\", epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "print(model(X))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.3309504985809326\n",
      "100 0.6948732733726501\n",
      "200 0.6918835043907166\n",
      "300 0.6903694868087769\n",
      "400 0.6859269142150879\n",
      "500 0.6719667911529541\n",
      "600 0.6381361484527588\n",
      "700 0.5848764181137085\n",
      "800 0.5269197821617126\n",
      "900 0.4761895537376404\n",
      "1000 0.4280622601509094\n",
      "1100 0.372464120388031\n",
      "1200 0.3064245581626892\n",
      "1300 0.2388092279434204\n",
      "1400 0.1816982477903366\n",
      "1500 0.13937939703464508\n",
      "1600 0.10957132279872894\n",
      "1700 0.08858106285333633\n",
      "1800 0.07348067313432693\n",
      "1900 0.06231287494301796\n",
      "2000 0.05382362753152847\n",
      "2100 0.047207269817590714\n",
      "2200 0.04193601384758949\n",
      "2300 0.0376550629734993\n",
      "2400 0.03412013128399849\n",
      "2500 0.03115866705775261\n",
      "2600 0.028646118938922882\n",
      "2700 0.02649061754345894\n",
      "2800 0.024623310193419456\n",
      "2900 0.02299145795404911\n",
      "3000 0.02155422978103161\n",
      "3100 0.02027968131005764\n",
      "3200 0.0191422738134861\n",
      "3300 0.018121372908353806\n",
      "3400 0.017200399190187454\n",
      "3500 0.016365595161914825\n",
      "3600 0.015605677850544453\n",
      "3700 0.0149111682549119\n",
      "3800 0.014274059794843197\n",
      "3900 0.013687780126929283\n",
      "4000 0.013146381825208664\n",
      "4100 0.012645132839679718\n",
      "4200 0.012179771438241005\n",
      "4300 0.011746559292078018\n",
      "4400 0.01134237740188837\n",
      "4500 0.010964441113173962\n",
      "4600 0.010610368102788925\n",
      "4700 0.010277869179844856\n",
      "4800 0.009965131990611553\n",
      "4900 0.009670446626842022\n",
      "5000 0.009392337873578072\n",
      "5100 0.009129466488957405\n",
      "5200 0.008880538865923882\n",
      "5300 0.008644629269838333\n",
      "5400 0.008420674130320549\n",
      "5500 0.008207776583731174\n",
      "5600 0.008005193434655666\n",
      "5700 0.007812210824340582\n",
      "5800 0.007628103252500296\n",
      "5900 0.007452324032783508\n",
      "6000 0.007284357212483883\n",
      "6100 0.007123568095266819\n",
      "6200 0.006969698239117861\n",
      "6300 0.006822187919169664\n",
      "6400 0.006680705118924379\n",
      "6500 0.0065448107197880745\n",
      "6600 0.006414338480681181\n",
      "6700 0.006288849748671055\n",
      "6800 0.006168073508888483\n",
      "6900 0.006051752250641584\n",
      "7000 0.005939674563705921\n",
      "7100 0.005831659305840731\n",
      "7200 0.00572740426287055\n",
      "7300 0.005626789294183254\n",
      "7400 0.00552954338490963\n",
      "7500 0.005435619968920946\n",
      "7600 0.005344748497009277\n",
      "7700 0.005256837233901024\n",
      "7800 0.0051716770976781845\n",
      "7900 0.005089236423373222\n",
      "8000 0.005009365733712912\n",
      "8100 0.00493185268715024\n",
      "8200 0.004856758750975132\n",
      "8300 0.0047838119789958\n",
      "8400 0.004713043104857206\n",
      "8500 0.004644286353141069\n",
      "8600 0.004577510990202427\n",
      "8700 0.004512597341090441\n",
      "8800 0.004449469968676567\n",
      "8900 0.004388009198009968\n",
      "9000 0.004328273236751556\n",
      "9100 0.004270083736628294\n",
      "9200 0.004213424399495125\n",
      "9300 0.0041582053527235985\n",
      "9400 0.004104441497474909\n",
      "9500 0.004051982890814543\n",
      "9600 0.004000889137387276\n",
      "9700 0.003951025195419788\n",
      "9800 0.003902316326275468\n",
      "9900 0.003854866838082671\n",
      "10000 0.003808571957051754\n"
     ]
    }
   ],
   "source": [
    "# Backpropagation implementation\n",
    "# XOR by Multiple Layer\n",
    "\n",
    "import torch\n",
    "\n",
    "X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)\n",
    "Y = torch.tensor([[0],[1],[1],[0]], dtype=torch.float32)\n",
    "\n",
    "# ???\n",
    "w1 = torch.Tensor(2,1)\n",
    "b1 = torch.Tensor(2)\n",
    "w2 = torch.Tensor(2,1)\n",
    "b2 = torch.Tensor(1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + torch.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "for step in range(10000 + 1):\n",
    "    # forward pass. Multi Layer\n",
    "    l1 = torch.add(torch.matmul(X, w1), b1) # w1*X + b1\n",
    "    a1 = sigmoid(l1) # sigmoid(w1*X + b1)\n",
    "    l2 = torch.add(torch.matmul(a1, w2), b2) # w2*a1 + b2\n",
    "    Y_pred = sigmoid(l2) # sigmoid(w2*a1 + b2)\n",
    "    \n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred)) # B-Cross Entropy\n",
    "    \n",
    "    # backwward Propagation : chain rule까지 적용된 결과\n",
    "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1. - Y_pred) + 0.00000001) # Loss : B-Cross Entropy의 미분\n",
    "    # Layer 2\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2 # 1 * d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_l2) # w2*X + b2를 w2로 미분하면 X만 남는다.\n",
    "    # d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
    "    # Layer 1\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2,0,1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1 \n",
    "    d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_l1)\n",
    "    # d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_b1)\n",
    "    \n",
    "    # Update process\n",
    "    w1 = w1 - learning_rate * d_w1\n",
    "    b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
    "    w2 = w2 - learning_rate * d_w2\n",
    "    b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0023],\n",
      "        [0.9952],\n",
      "        [0.9952],\n",
      "        [0.0033]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7013025283813477\n",
      "100 0.6910400986671448\n",
      "200 0.6685031056404114\n",
      "300 0.5564861297607422\n",
      "400 0.36737060546875\n",
      "500 0.1381683349609375\n",
      "600 0.06692102551460266\n",
      "700 0.04205302149057388\n",
      "800 0.03019404225051403\n",
      "900 0.02339489758014679\n",
      "1000 0.019027316942811012\n",
      "1100 0.015999939292669296\n",
      "1200 0.01378466933965683\n",
      "1300 0.012096784077584743\n",
      "1400 0.010769703425467014\n",
      "1500 0.009700112044811249\n",
      "1600 0.008820261806249619\n",
      "1700 0.008084287866950035\n",
      "1800 0.007459857501089573\n",
      "1900 0.006923528388142586\n",
      "2000 0.006458045914769173\n",
      "2100 0.006050391122698784\n",
      "2200 0.005690417252480984\n",
      "2300 0.0053703803569078445\n",
      "2400 0.005083948373794556\n",
      "2500 0.004826163873076439\n",
      "2600 0.004592944867908955\n",
      "2700 0.00438095023855567\n",
      "2800 0.004187471698969603\n",
      "2900 0.00401014881208539\n",
      "3000 0.0038470569998025894\n",
      "3100 0.003696588333696127\n",
      "3200 0.003557301592081785\n",
      "3300 0.0034280845429748297\n",
      "3400 0.0033077667467296124\n",
      "3500 0.0031955528538674116\n",
      "3600 0.003090647514909506\n",
      "3700 0.002992300782352686\n",
      "3800 0.0028999727219343185\n",
      "3900 0.0028131529688835144\n",
      "4000 0.0027313027530908585\n",
      "4100 0.002654031850397587\n",
      "4200 0.002580996137112379\n",
      "4300 0.002511804923415184\n",
      "4400 0.002446249360218644\n",
      "4500 0.0023839545901864767\n",
      "4600 0.002324711298570037\n",
      "4700 0.002268369309604168\n",
      "4800 0.0022146592382341623\n",
      "4900 0.0021634164731949568\n",
      "5000 0.002114416565746069\n",
      "5100 0.00206761434674263\n",
      "5200 0.0020228305365890265\n",
      "5300 0.0019799298606812954\n",
      "5400 0.0019387634238228202\n",
      "5500 0.0018992859404534101\n",
      "5600 0.0018613776192069054\n",
      "5700 0.0018249191343784332\n",
      "5800 0.001789879985153675\n",
      "5900 0.001756111392751336\n",
      "6000 0.0017236722633242607\n",
      "6100 0.0016923240618780255\n",
      "6200 0.0016620964743196964\n",
      "6300 0.0016329147620126605\n",
      "6400 0.001604733755812049\n",
      "6500 0.0015775240026414394\n",
      "6600 0.0015511952806264162\n",
      "6700 0.001525777974165976\n",
      "6800 0.0015011224895715714\n",
      "6900 0.0014772138092666864\n",
      "7000 0.0014541115378960967\n",
      "7100 0.0014316813321784139\n",
      "7200 0.0014099681284278631\n",
      "7300 0.001388896955177188\n",
      "7400 0.0013684232253581285\n",
      "7500 0.0013485319213941693\n",
      "7600 0.0013292080257087946\n",
      "7700 0.0013104365207254887\n",
      "7800 0.0012921429006382823\n",
      "7900 0.0012744017876684666\n",
      "8000 0.0012571532279253006\n",
      "8100 0.0012402930296957493\n",
      "8200 0.0012239553034305573\n",
      "8300 0.0012079909211024642\n",
      "8400 0.001192429568618536\n",
      "8500 0.0011772713623940945\n",
      "8600 0.0011625309707596898\n",
      "8700 0.001148104202002287\n",
      "8800 0.0011340656783431768\n",
      "8900 0.0011203106259927154\n",
      "9000 0.0011069139000028372\n",
      "9100 0.0010938305640593171\n",
      "9200 0.0010810756357386708\n",
      "9300 0.001068589510396123\n",
      "9400 0.001056356937624514\n",
      "9500 0.0010444229701533914\n",
      "9600 0.001032772590406239\n",
      "9700 0.0010213609784841537\n",
      "9800 0.001010218053124845\n",
      "9900 0.0009993438143283129\n",
      "10000 0.0009886336047202349\n",
      "tensor([[8.5134e-04],\n",
      "        [9.9911e-01],\n",
      "        [9.9911e-01],\n",
      "        [1.3274e-03]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 이어서 xor를 high level 구현으로 풀어본다.\n",
    "# Single Layer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)\n",
    "Y = torch.tensor([[0],[1],[1],[0]], dtype=torch.float32)\n",
    "\n",
    "linear1 = nn.Linear(2,2,bias=True)\n",
    "linear2 = nn.Linear(2,1,bias=True)\n",
    "sigmoid = nn.Sigmoid()\n",
    "model = nn.Sequential(linear1, sigmoid, linear2, sigmoid)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(10000 + 1):\n",
    "    hypothesis = model(X)\n",
    "    cost = F.binary_cross_entropy(hypothesis, Y)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())\n",
    "print(model(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6995787620544434\n",
      "100 0.6931189894676208\n",
      "200 0.6931160688400269\n",
      "300 0.6931127905845642\n",
      "400 0.693109393119812\n",
      "500 0.6931055188179016\n",
      "600 0.6931014657020569\n",
      "700 0.6930969953536987\n",
      "800 0.6930919885635376\n",
      "900 0.6930864453315735\n",
      "1000 0.6930801272392273\n",
      "1100 0.693073034286499\n",
      "1200 0.6930650472640991\n",
      "1300 0.6930557489395142\n",
      "1400 0.6930451393127441\n",
      "1500 0.6930326223373413\n",
      "1600 0.693017840385437\n",
      "1700 0.6930001974105835\n",
      "1800 0.6929787397384644\n",
      "1900 0.6929523944854736\n",
      "2000 0.6929193735122681\n",
      "2100 0.6928770542144775\n",
      "2200 0.6928216814994812\n",
      "2300 0.6927469372749329\n",
      "2400 0.692642092704773\n",
      "2500 0.6924887299537659\n",
      "2600 0.6922504901885986\n",
      "2700 0.6918508410453796\n",
      "2800 0.6911025047302246\n",
      "2900 0.689449667930603\n",
      "3000 0.6845925450325012\n",
      "3100 0.6584906578063965\n",
      "3200 0.4794733226299286\n",
      "3300 0.02082980051636696\n",
      "3400 0.00692561361938715\n",
      "3500 0.003891710191965103\n",
      "3600 0.0026430280413478613\n",
      "3700 0.0019775887485593557\n",
      "3800 0.0015689211431890726\n",
      "3900 0.0012944522313773632\n",
      "4000 0.0010982801904901862\n",
      "4100 0.0009515660931356251\n",
      "4200 0.0008379848441109061\n",
      "4300 0.0007476219325326383\n",
      "4400 0.0006740883691236377\n",
      "4500 0.0006132199196144938\n",
      "4600 0.0005620319861918688\n",
      "4700 0.000518405984621495\n",
      "4800 0.0004808051744475961\n",
      "4900 0.00044808085658587515\n",
      "5000 0.000419353018514812\n",
      "5100 0.0003940249443985522\n",
      "5200 0.0003714105987455696\n",
      "5300 0.0003511669929139316\n",
      "5400 0.00033290640567429364\n",
      "5500 0.00031639018561691046\n",
      "5600 0.0003014543035533279\n",
      "5700 0.00028774089878425\n",
      "5800 0.0002751903375610709\n",
      "5900 0.00026365352096036077\n",
      "6000 0.0002530260826461017\n",
      "6100 0.0002431737957522273\n",
      "6200 0.0002340221544727683\n",
      "6300 0.00022554132738150656\n",
      "6400 0.00021756729984190315\n",
      "6500 0.00021017463586758822\n",
      "6600 0.00020325896912254393\n",
      "6700 0.0001967457792488858\n",
      "6800 0.00019064993830397725\n",
      "6900 0.0001848671236075461\n",
      "7000 0.0001794718555174768\n",
      "7100 0.00017432999447919428\n",
      "7200 0.00016948621487244964\n",
      "7300 0.00016483623767271638\n",
      "7400 0.00016051414422690868\n",
      "7500 0.00015632621943950653\n",
      "7600 0.00015239164349623024\n",
      "7700 0.00014860615192446858\n",
      "7800 0.0001450442214263603\n",
      "7900 0.00014161643048282713\n",
      "8000 0.00013833768025506288\n",
      "8100 0.00013523778761737049\n",
      "8200 0.00013222733105067164\n",
      "8300 0.0001293659006478265\n",
      "8400 0.00012660880747716874\n",
      "8500 0.00012398585386108607\n",
      "8600 0.00012143742060288787\n",
      "8700 0.00011899331002496183\n",
      "8800 0.00011665353667922318\n",
      "8900 0.00011440319212852046\n",
      "9000 0.00011222735338378698\n",
      "9100 0.00011011114111170173\n",
      "9200 0.00010811415268108249\n",
      "9300 0.00010616188228596002\n",
      "9400 0.0001042841249727644\n",
      "9500 0.00010243616998195648\n",
      "9600 0.00010069254494737834\n",
      "9700 9.899363794829696e-05\n",
      "9800 9.736923675518483e-05\n",
      "9900 9.574484283803031e-05\n",
      "10000 9.42396727623418e-05\n",
      "tensor([[6.5585e-05],\n",
      "        [9.9991e-01],\n",
      "        [9.9991e-01],\n",
      "        [1.3235e-04]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 더 깊은 Layer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)\n",
    "Y = torch.tensor([[0],[1],[1],[0]], dtype=torch.float32)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(2,10,bias=True),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(10,10,bias=True),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(10,10,bias=True),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(10,1,bias=True),\n",
    "                      nn.Sigmoid())\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(10000 + 1):\n",
    "    hypothesis = model(X)\n",
    "    cost = F.binary_cross_entropy(hypothesis, Y)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())\n",
    "print(model(X))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
